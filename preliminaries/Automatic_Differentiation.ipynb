{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Automatic_Differentiation.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p9Hg4VQrWUXP",
        "outputId": "bebc3fe9-676b-4ba0-bc1e-a18e0b446fad"
      },
      "source": [
        "import torch\n",
        "\n",
        "x = torch.arange(4.0)\n",
        "x"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0., 1., 2., 3.])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "adMGvaUCW0yL"
      },
      "source": [
        "x.requires_grad_(True)  # Same as `x = torch.arange(4.0, requires_grad=True)`\n",
        "x.grad  # The default value is None"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mIOCWZFNW01C",
        "outputId": "f221745d-ec49-430c-e031-9e508553f88d"
      },
      "source": [
        "y = 2 * torch.dot(x, x)\n",
        "y"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(28., grad_fn=<MulBackward0>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EShwEsdnW036",
        "outputId": "c011673a-5838-4225-ba57-e9b608a0f897"
      },
      "source": [
        "y.backward()\n",
        "x.grad"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([ 0.,  4.,  8., 12.])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bP46WryaXTvT",
        "outputId": "bce589f3-2b2f-4442-d325-9b6f6d82064d"
      },
      "source": [
        "x.grad == 4 * x"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([True, True, True, True])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GGnuYt5eXTyI",
        "outputId": "250952b8-c985-4250-a427-4381216c2600"
      },
      "source": [
        "# PyTorch accumulates the gradient in default, we need to clear the previous\n",
        "# values\n",
        "x.grad.zero_()\n",
        "y = x.sum()\n",
        "print(x.sum())\n",
        "y.backward()\n",
        "x.grad"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor(6., grad_fn=<SumBackward0>)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1., 1., 1., 1.])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OYQvJzC3byAQ"
      },
      "source": [
        "## Backward for Non-Scalar Variables"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LPWVR0awXT0y",
        "outputId": "d935ccb1-0c14-4f47-c6e4-66cbc3323eb2"
      },
      "source": [
        "x.grad.zero_()\n",
        "print(x)\n",
        "y = x * x\n",
        "# y.backward(torch.ones(len(x))) equivalent to the below\n",
        "print(y)\n",
        "print(y.sum())\n",
        "y.sum().backward()\n",
        "x.grad"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([0., 1., 2., 3.], requires_grad=True)\n",
            "tensor([0., 1., 4., 9.], grad_fn=<MulBackward0>)\n",
            "tensor(14., grad_fn=<SumBackward0>)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0., 2., 4., 6.])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cWdMq4DtXT27",
        "outputId": "89953dcc-6e7e-40cf-a79c-faa26235e2fd"
      },
      "source": [
        "# Invoking `backward` on a non-scalar requires passing in a `gradient` argument\n",
        "# which specifies the gradient of the differentiated function w.r.t `self`.\n",
        "# In our case, we simply want to sum the partial derivatives, so passing\n",
        "# in a gradient of ones is appropriate\n",
        "x.grad.zero_()\n",
        "y = x * x\n",
        "y.backward(torch.ones(len(x))) #equivalent to the below\n",
        "print(len(x))\n",
        "print(torch.ones(len(x)))\n",
        "#y.sum().backward()\n",
        "x.grad"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "4\n",
            "tensor([1., 1., 1., 1.])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0., 2., 4., 6.])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rp2WEOopc05_"
      },
      "source": [
        "## Detaching Computation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m5XZBBUhW06y",
        "outputId": "220e1a67-7868-4a0f-b1a3-bb79a935b4ae"
      },
      "source": [
        "x.grad.zero_()\n",
        "y = x * x\n",
        "u = y.detach()\n",
        "z = u * x\n",
        "\n",
        "z.sum().backward()\n",
        "x.grad == u"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([True, True, True, True])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KaMbp06TW09Q",
        "outputId": "a183e0a0-e85d-4932-c3c5-e0e29a9d831b"
      },
      "source": [
        "x.grad.zero_()\n",
        "y.sum().backward()\n",
        "x.grad == 2 * x"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([True, True, True, True])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-KSWIheIeHQ0"
      },
      "source": [
        "## Computing the Gradient of Python Control Flow"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tWRO-hQffXjG"
      },
      "source": [
        "In the control flow example where we calculate the derivative of d with respect to a, what would happen if we changed the variable a to a random vector or matrix. At this point, the result of the calculation f(a) is no longer a scalar. What happens to the result? How do we analyze this?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0l2RcEnueGnu"
      },
      "source": [
        "def f(a):\n",
        "    b = a * 2\n",
        "    while b.norm() < 1000:\n",
        "        b = b * 2\n",
        "    if b.sum() > 0:\n",
        "        c = b\n",
        "    else:\n",
        "        c = 100 * b\n",
        "    return c"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RVezvXtxeGql"
      },
      "source": [
        "a = torch.randn(size=(), requires_grad=True)\n",
        "d = f(a)\n",
        "d.backward()"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jzl6ZNYUeGsq",
        "outputId": "de03a49c-0a23-42b6-a146-7a485d5473b0"
      },
      "source": [
        "a.grad == d / a"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(True)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H11lW5OrW0_9",
        "outputId": "60719ea1-c6c1-4a0e-ef52-63a12628fb9b"
      },
      "source": [
        "demo = torch.tensor([3,4], dtype = torch.float64)\n",
        "demo.norm()"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(5., dtype=torch.float64)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JJrfDsHdelhA",
        "outputId": "51421505-e8e1-4994-8b37-2d17db2de89b"
      },
      "source": [
        "demo = torch.tensor([3,4], dtype = torch.float32)\n",
        "demo.norm()"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(5.)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J1o1tzfDeo4J"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}